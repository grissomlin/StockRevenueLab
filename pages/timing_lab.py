import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import urllib.parse
import plotly.express as px
import plotly.graph_objects as go

# ========== 1. é é¢é…ç½® ==========
st.set_page_config(page_title="å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ | StockRevenueLab", layout="wide")

# ========== 2. å®‰å…¨è³‡æ–™åº«é€£ç·š ==========
@st.cache_resource
def get_engine():
    try:
        DB_PASSWORD = st.secrets["DB_PASSWORD"]
        PROJECT_REF = st.secrets["PROJECT_REF"]
        POOLER_HOST = st.secrets["POOLER_HOST"]
        encoded_password = urllib.parse.quote_plus(DB_PASSWORD)
        connection_string = f"postgresql://postgres.{PROJECT_REF}:{encoded_password}@{POOLER_HOST}:5432/postgres?sslmode=require"
        return create_engine(connection_string)
    except Exception:
        st.error("âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—")
        st.stop()

# ========== 3. ç¹ªåœ–è¼”åŠ©å‡½æ•¸ (é—œéµï¼šè¨ˆç®—åˆ†ä½ˆä¸¦æ¨™è¨») ==========
def create_enhanced_hist(df, col_name, title, color):
    if df[col_name].dropna().empty:
        return go.Figure()
    
    # 1. è¨ˆç®—åˆ†ä½ˆæ•¸æ“š
    counts, bins = np.histogram(df[col_name].dropna(), bins=20)
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    total = len(df)
    percentages = (counts / total) * 100
    
    # 2. å»ºç«‹æ¨™ç±¤æ–‡å­— (ä¾‹å¦‚: 15æª”\n12.5%)
    texts = [f"{int(c)}æª”<br>{p:.1f}%" if c > 0 else "" for c, p in zip(counts, percentages)]
    
    # 3. ä½¿ç”¨ go.Bar ç¹ªåœ–ä»¥ç²å¾—æœ€å¤§æ§åˆ¶æ¬Š
    fig = go.Figure(data=[
        go.Bar(
            x=bin_centers,
            y=counts,
            text=texts,
            textposition='outside',
            marker_color=color,
            hovertemplate="å€é–“: %{x:.2f}%<br>å®¶æ•¸: %{y}æª”<br>æ¯”ä¾‹: %{text}<extra></extra>"
        )
    ])
    
    fig.add_vline(x=0, line_dash="dash", line_color="black")
    fig.update_layout(
        title=title,
        xaxis_title="æ¼²è·Œå¹… %",
        yaxis_title="å®¶æ•¸",
        margin=dict(t=50, b=20, l=10, r=10),
        height=350,
        showlegend=False
    )
    return fig

# ========== 4. æ ¸å¿ƒæ¨™é¡Œ ==========
st.title("ğŸ•µï¸ ç‡Ÿæ”¶å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ 2.0")

# --- å´é‚Šæ¬„æ§åˆ¶ ---
with st.sidebar:
    st.header("ğŸ”¬ ç­–ç•¥åƒæ•¸è¨­å®š")
    target_year = st.selectbox("åˆ†æå¹´åº¦", [str(y) for y in range(2025, 2019, -1)], index=1)
    study_metric = st.radio("æˆé•·æŒ‡æ¨™", ["yoy_pct", "mom_pct"])
    threshold = st.slider(f"è¨­å®š {study_metric} çˆ†ç™¼é–€æª» %", 30, 300, 100)
    search_remark = st.text_input("ğŸ” å‚™è¨»é—œéµå­— (å¦‚: è¨‚å–®, æ—¥æœ¬, äº¤å±‹)", "")

# --- æ ¸å¿ƒ SQL ---
@st.cache_data(ttl=3600)
def fetch_timing_data(year, metric_col, limit, keyword):
    engine = get_engine()
    minguo_year = int(year) - 1911
    query = f"""
    WITH raw_events AS (
        SELECT stock_id, stock_name, report_month, {metric_col}, remark,
               LAG({metric_col}) OVER (PARTITION BY stock_id ORDER BY report_month) as prev_metric
        FROM monthly_revenue
        WHERE report_month LIKE '{minguo_year}_%' OR report_month LIKE '{int(minguo_year)-1}_12'
    ),
    spark_events AS (
        SELECT *,
               CASE 
                 WHEN RIGHT(report_month, 2) = '12' THEN (LEFT(report_month, 3)::int + 1 + 1911)::text || '-01-10'
                 ELSE (LEFT(report_month, 3)::int + 1911)::text || '-' || LPAD((RIGHT(report_month, 2)::int + 1)::text, 2, '0') || '-10'
               END::date as base_date
        FROM raw_events
        WHERE {metric_col} >= {limit} 
          AND (prev_metric < {limit} OR prev_metric IS NULL)
          AND report_month LIKE '{minguo_year}_%'
          AND (remark LIKE '%%{keyword}%%' OR stock_name LIKE '%%{keyword}%%')
    ),
    weekly_calc AS (
        SELECT symbol, date, w_close,
               (w_close - LAG(w_close) OVER (PARTITION BY symbol ORDER BY date)) / 
               NULLIF(LAG(w_close) OVER (PARTITION BY symbol ORDER BY date), 0) * 100 as weekly_ret
        FROM stock_weekly_k
    ),
    final_detail AS (
        SELECT 
            e.stock_id, e.stock_name, e.report_month, 
            ROUND(e.{metric_col}::numeric, 2) as growth_val, 
            e.remark,
            ROUND(AVG(CASE WHEN c.date >= e.base_date - interval '9 days' AND c.date <= e.base_date - interval '3 days' THEN c.weekly_ret END)::numeric, 2) as pre_week,
            ROUND(AVG(CASE WHEN c.date > e.base_date - interval '3 days' AND c.date <= e.base_date + interval '4 days' THEN c.weekly_ret END)::numeric, 2) as announce_week,
            ROUND(AVG(CASE WHEN c.date > e.base_date + interval '4 days' AND c.date <= e.base_date + interval '11 days' THEN c.weekly_ret END)::numeric, 2) as after_week_1,
            ROUND(AVG(CASE WHEN c.date > e.base_date + interval '11 days' AND c.date <= e.base_date + interval '30 days' THEN c.weekly_ret END)::numeric, 2) as after_month
        FROM spark_events e
        JOIN weekly_calc c ON e.stock_id = SPLIT_PART(c.symbol, '.', 1)
        GROUP BY e.stock_id, e.stock_name, e.report_month, e.{metric_col}, e.remark, e.base_date
    )
    SELECT * FROM final_detail WHERE pre_week IS NOT NULL ORDER BY pre_week DESC;
    """
    with engine.connect() as conn:
        return pd.read_sql_query(text(query), conn)

df = fetch_timing_data(target_year, study_metric, threshold, search_remark)

if not df.empty:
    # --- A. çµ±è¨ˆçœ‹æ¿ ---
    total_n = len(df)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æ¨£æœ¬ç¸½æ•¸", f"{total_n}")
    c2.metric("T-1 é è·‘å‹ç‡", f"{(df['pre_week']>0).sum()/total_n*100:.1f}%")
    c3.metric("T-1 å¹³å‡å ±é…¬", f"{df['pre_week'].mean():.2f}%")
    c4.metric("åˆ©å¤šå‡ºç›¡æ¯”ä¾‹", f"{(df['after_month'] < df['pre_week']).sum()/total_n*100:.1f}%")

    st.write("---")
    
    # --- B. åˆè™Ÿæ©Ÿå€‹è‚¡æ¸…å–® ---
    st.subheader(f"ğŸ† {target_year} å¹´ åˆè™Ÿæ©Ÿæ¸…å–® (å››éšæ®µå°ç…§)")
    display_df = df.rename(columns={
        "stock_id": "ä»£è™Ÿ", "stock_name": "åç¨±", "report_month": "æœˆä»½",
        "growth_val": f"{study_metric}%", 
        "pre_week": "T-1å‘¨(é è·‘)%", "announce_week": "Tå‘¨(å…¬å‘Š)%", 
        "after_week_1": "T+1å‘¨(å¾ŒçºŒ)%", "after_month": "ä¸€å€‹æœˆå¾Œ%", "remark": "å‚™è¨»"
    })

    st.dataframe(
        display_df.style.background_gradient(subset=["T-1å‘¨(é è·‘)%", "Tå‘¨(å…¬å‘Š)%", "T+1å‘¨(å¾ŒçºŒ)%", "ä¸€å€‹æœˆå¾Œ%"], cmap="RdYlGn"),
        use_container_width=True, height=450,
        column_config={
            f"{study_metric}%": st.column_config.NumberColumn(format="%.2f"),
            "å‚™è¨»": st.column_config.TextColumn(width="large")
        }
    )

    st.write("---")

    # --- C. å››å¼µåˆ†å¸ƒåœ– (åº•éƒ¨ä¸¦æ’ï¼Œé¡¯ç¤ºå®¶æ•¸èˆ‡æ¯”ä¾‹) ---
    st.subheader("ğŸ“Š éšæ®µå ±é…¬ç‡åˆ†ä½ˆå°ç…§ (å«å®¶æ•¸èˆ‡æ¯”ä¾‹æ¨™è¨˜)")
    
    row1_col1, row1_col2 = st.columns(2)
    row2_col1, row2_col2 = st.columns(2)

    with row1_col1:
        st.plotly_chart(create_enhanced_hist(df, "pre_week", "â¶ T-1 å‘¨ (å…¬å‘Šå‰å¤•)", "#ff4b4b"), use_container_width=True)
    with row1_col2:
        st.plotly_chart(create_enhanced_hist(df, "announce_week", "â· T å‘¨ (å…¬å‘Šç•¶å‘¨)", "#ffaa00"), use_container_width=True)
    with row2_col1:
        st.plotly_chart(create_enhanced_hist(df, "after_week_1", "â¸ T+1 å‘¨ (å…¬å‘Šå¾Œä¸€å‘¨)", "#32cd32"), use_container_width=True)
    with row2_col2:
        st.plotly_chart(create_enhanced_hist(df, "after_month", "â¹ å…¬å‘Šå¾Œä¸€å€‹æœˆ", "#1e90ff"), use_container_width=True)

else:
    st.info("ğŸ’¡ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„å…¬å¸ã€‚")
