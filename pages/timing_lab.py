import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import urllib.parse
import plotly.graph_objects as go
import os
from scipy.stats import skew, kurtosis

# å˜—è©¦åŒ¯å…¥ AI å¥—ä»¶
try:
    import google.generativeai as genai
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

# ========== 1. é é¢é…ç½® ==========
st.set_page_config(page_title="å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ 5.1 | å…¨ç¶­åº¦è¨ºæ–·", layout="wide")

# ========== 2. å®‰å…¨è³‡æ–™åº«é€£ç·š ==========
@st.cache_resource
def get_engine():
    try:
        DB_PASSWORD = st.secrets["DB_PASSWORD"]
        PROJECT_REF = st.secrets["PROJECT_REF"]
        POOLER_HOST = st.secrets["POOLER_HOST"]
        encoded_password = urllib.parse.quote_plus(DB_PASSWORD)
        connection_string = f"postgresql://postgres.{PROJECT_REF}:{encoded_password}@{POOLER_HOST}:5432/postgres?sslmode=require"
        return create_engine(connection_string)
    except Exception:
        st.error("âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—")
        st.stop()

# ========== 3. æ•¸æ“šè¼”åŠ©å‡½æ•¸ ==========
def get_ai_summary_dist(df, col_name):
    data = df[col_name].dropna()
    if data.empty: return "ç„¡æ•¸æ“š"
    total = len(data)
    bins = [-float('inf'), -5, -1, 1, 5, float('inf')]
    labels = ["å¤§è·Œ(<-5%)", "å°è·Œ", "æŒå¹³", "å°æ¼²", "å¤§æ¼²(>5%)"]
    counts, _ = np.histogram(data, bins=bins)
    return " / ".join([f"{l}:{int(c)}æª”({(c/total*100):.1f}%)" for l, c in zip(labels, counts) if c > 0])

def create_big_hist(df, col_name, title, color, desc):
    """ç¹ªè£½ç›´æ–¹åœ–ä¸¦é¡¯ç¤ºä¸­ä½æ•¸èˆ‡å¹³å‡ç·š"""
    data = df[col_name].dropna()
    if data.empty: return
    
    mean_val = data.mean()
    median_val = data.median()
    
    counts, bins = np.histogram(data, bins=25)
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    texts = [f"<b>{int(c)}æª”</b>" for c in counts]
    
    fig = go.Figure(data=[go.Bar(x=bin_centers, y=counts, text=texts, textposition='outside', marker_color=color)])
    
    fig.add_vline(x=0, line_dash="dash", line_color="black", line_width=1)
    fig.add_vline(x=mean_val, line_color="red", line_width=2, annotation_text=f"å¹³å‡ {mean_val:.1f}%")
    fig.add_vline(x=median_val, line_color="blue", line_width=2, annotation_text=f"ä¸­ä½ {median_val:.1f}%", annotation_position="bottom right")
    
    fig.update_layout(title=dict(text=title, font=dict(size=20)), height=400, margin=dict(t=80, b=40))
    st.plotly_chart(fig, use_container_width=True)
    st.info(f"ğŸ’¡ **ç§‘å­¸è§£è®€ï¼š** {desc}")
    st.markdown("---")

# ========== 4. æ ¸å¿ƒ SQL é‚è¼¯ (åˆæ¬¡çˆ†ç™¼) ==========
@st.cache_data(ttl=3600)
def fetch_timing_data(year, metric_col, limit, keyword):
    engine = get_engine()
    minguo_year = int(year) - 1911
    query = f"""
    WITH raw_events AS (
        SELECT stock_id, stock_name, report_month, {metric_col}, remark,
               LAG({metric_col}) OVER (PARTITION BY stock_id ORDER BY report_month) as prev_metric
        FROM monthly_revenue
        WHERE report_month LIKE '{minguo_year}_%' OR report_month LIKE '{int(minguo_year)-1}_12'
    ),
    spark_events AS (
        SELECT *,
               CASE 
                 WHEN RIGHT(report_month, 2) = '12' THEN (LEFT(report_month, 3)::int + 1 + 1911)::text || '-01-10'
                 ELSE (LEFT(report_month, 3)::int + 1911)::text || '-' || LPAD((RIGHT(report_month, 2)::int + 1)::text, 2, '0') || '-10'
               END::date as base_date
        FROM raw_events
        WHERE {metric_col} >= {limit} 
          AND (prev_metric < {limit} OR prev_metric IS NULL)
          AND report_month LIKE '{minguo_year}_%'
          AND (remark LIKE '%%{keyword}%%' OR stock_name LIKE '%%{keyword}%%')
    ),
    weekly_calc AS (
        SELECT symbol, date, w_close,
               (w_close - LAG(w_close) OVER (PARTITION BY symbol ORDER BY date)) / 
               NULLIF(LAG(w_close) OVER (PARTITION BY symbol ORDER BY date), 0) * 100 as weekly_ret
        FROM stock_weekly_k
    ),
    final_detail AS (
        SELECT 
            e.stock_id, e.stock_name, e.report_month, e.{metric_col} as growth_val, e.remark,
            AVG(CASE WHEN c.date >= e.base_date - interval '38 days' AND c.date < e.base_date - interval '9 days' THEN c.weekly_ret END) * 4 as pre_month,
            AVG(CASE WHEN c.date >= e.base_date - interval '9 days' AND c.date <= e.base_date - interval '3 days' THEN c.weekly_ret END) as pre_week,
            AVG(CASE WHEN c.date > e.base_date - interval '3 days' AND c.date <= e.base_date + interval '4 days' THEN c.weekly_ret END) as announce_week,
            AVG(CASE WHEN c.date > e.base_date + interval '4 days' AND c.date <= e.base_date + interval '11 days' THEN c.weekly_ret END) as after_week_1,
            AVG(CASE WHEN c.date > e.base_date + interval '11 days' AND c.date <= e.base_date + interval '30 days' THEN c.weekly_ret END) as after_month
        FROM spark_events e
        JOIN weekly_calc c ON e.stock_id = SPLIT_PART(c.symbol, '.', 1)
        GROUP BY e.stock_id, e.stock_name, e.report_month, e.{metric_col}, e.remark, e.base_date
    )
    SELECT * FROM final_detail WHERE pre_week IS NOT NULL ORDER BY pre_month DESC;
    """
    with engine.connect() as conn:
        return pd.read_sql_query(text(query), conn)

# ========== 5. ä»‹é¢èˆ‡çµ±è¨ˆå‘ˆç¾ ==========
with st.sidebar:
    st.header("ğŸ”¬ åƒæ•¸è¨­å®š")
    target_year = st.sidebar.selectbox("åˆ†æå¹´åº¦", [str(y) for y in range(2025, 2019, -1)], index=1)
    study_metric = st.radio("æŒ‡æ¨™", ["yoy_pct", "mom_pct"])
    threshold = st.slider(f"çˆ†ç™¼é–€æª» %", 30, 300, 100)
    search_remark = st.text_input("ğŸ” æœå°‹å‚™è¨»", "")

st.title(f"ğŸ•µï¸ {target_year} å¹´ å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ 5.1")

df = fetch_timing_data(target_year, study_metric, threshold, search_remark)

if not df.empty:
    # A. å…¨ç¶­åº¦çœ‹æ¿ (è£œé½Šæ‰€æœ‰æŒ‡æ¨™)
    total_n = len(df)
    
    def calc_stats(col):
        d = df[col].dropna()
        m, med = d.mean(), d.median()
        sk, ku = skew(d), kurtosis(d)
        cv = d.std() / abs(m) if m != 0 else 0
        return m, med, sk, ku, cv

    m_m, m_d, m_s, m_k, m_c = calc_stats('pre_month')
    w_m, w_d, w_s, w_k, w_c = calc_stats('pre_week')
    a_m, a_d, a_s, a_k, a_c = calc_stats('announce_week')
    aw_m, aw_d, aw_s, aw_k, aw_c = calc_stats('after_week_1')
    f_m, f_d, f_s, f_k, f_c = calc_stats('after_month')

    st.subheader("ğŸ”¬ è¡Œç‚ºçµ±è¨ˆçœ‹æ¿ (å¹³å‡/ä¸­ä½æ•¸å°ç…§)")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("æ¨£æœ¬ç¸½æ•¸", f"{total_n} æª”")
    c2.metric("T-1æœˆ (å¤§æˆ¶å€)", f"{m_m:.1f}%", f"ä¸­ä½: {m_d:.1f}%")
    c3.metric("T-1å‘¨ (é è·‘å€)", f"{w_m:.1f}%", f"ä¸­ä½: {w_d:.1f}%")
    c4.metric("Tå‘¨å…¬å‘Š (åæ‡‰å€)", f"{a_m:.1f}%", f"ä¸­ä½: {a_d:.1f}%")
    c5.metric("T+1æœˆ (çµå±€å€)", f"{f_m:.1f}%", f"ä¸­ä½: {f_d:.1f}%")
    
    st.markdown(f"""
    **ğŸ” çµ±è¨ˆæ·±æ¢ï¼š**
    * **T-1æœˆ**ï¼šååº¦ `{m_s:.2f}` (å³åä»£è¡¨å¤§æˆ¶ä½ˆå±€) | å³°åº¦ `{m_k:.2f}` (åšå°¾ä»£è¡¨æ¥µç«¯é£†è‚¡) | è®Šç•°ä¿‚æ•¸ `{m_c:.2f}`
    * **Tå‘¨å…¬å‘Š**ï¼šååº¦ `{a_s:.2f}` | å³°åº¦ `{a_k:.2f}`
    """)
    st.write("---")

    # B. åŸå§‹æ˜ç´°èˆ‡è¤‡è£½
    st.subheader("ğŸ† åŸå§‹æ•¸æ“šæ˜ç´°")
    col_dl, col_copy = st.columns([1, 4])
    with col_dl:
        st.download_button("ğŸ“‹ ä¸‹è¼‰ CSV", df.to_csv(index=False).encode('utf-8'), f"{target_year}_data.csv")
    with col_copy:
        if st.checkbox("ğŸ” ç”¢ç”Ÿ AI å³å°¾å¼·å‹¢è‚¡è¨ºæ–·æŒ‡ä»¤"):
            # é¸å– T-1æœˆ æ¼²å¹… > 5% çš„å€‹è‚¡
            tail_df = df[df['pre_month'] > 5]
            tail_list = tail_df[['stock_id', 'stock_name', 'pre_month', 'remark']].head(50).to_markdown(index=False)
            rt_prompt = (
                f"åˆ†æ {target_year} å¹´ç‡Ÿæ”¶çˆ†ç™¼è‚¡ã€‚ç¸½æ•¸ {total_n} æª”ã€‚\n"
                f"ã€çµ±è¨ˆè­‰æ“šã€‘ï¼šT-1æœˆå¹³å‡ {m_m:.1f}%, ä¸­ä½æ•¸ {m_d:.1f}%ã€‚ååº¦ {m_s:.2f} é¡¯ç¤ºæ¥µå¤§å³å°¾åå‘ã€‚\n"
                f"ã€å³å°¾å¼·å‹¢æ¨™çš„ (T-1æœˆ > 5%)ã€‘ï¼šå…± {len(tail_df)} æª”ï¼Œå¹³å‡æ¼²å¹… {tail_df['pre_month'].mean():.1f}%ã€‚\n"
                f"åå–®å¦‚ä¸‹ï¼š\n{tail_list}\n"
                f"è«‹åˆ†æé€™ç¾¤æ¨™çš„æ˜¯å¦å…·å‚™ã€è³‡è¨Šå…ˆè¡Œã€ç‰¹å¾µï¼Œä¸¦å»ºè­°å¦‚ä½•è­˜åˆ¥æ­¤é¡æ¨™çš„ã€‚"
            )
            st.code(rt_prompt, language="text")

    df['é€£çµ'] = df['stock_id'].apply(lambda x: f"https://www.wantgoo.com/stock/{x}/technical-chart")
    st.dataframe(df, use_container_width=True, height=400, column_config={"é€£çµ": st.column_config.LinkColumn("åœ–è¡¨", display_text="ğŸ”—")})
    st.write("---")

    # C. å®Œæ•´äº”å¼µåˆ†ä½ˆåœ– (Mean/Median ä¸¦åˆ—)
    st.subheader("ğŸ“Š å…¬å‘Šè¡Œç‚ºå„éšæ®µåˆ†ä½ˆè¶¨å‹¢")
    
    create_big_hist(df, "pre_month", "â“ª T-1 æœˆ (å¤§æˆ¶ä½ˆå±€å€)", "#8a2be2", "å…¬å‘Šå‰ä¸€å€‹æœˆã€‚è‹¥å¹³å‡å€¼åœ¨ç´…ç·šå³æ–¹ä¸”é é›¢è—ç·šï¼Œå³ç‚ºå¤§æˆ¶ææ—©å¡ä½è­‰æ“šã€‚")
    create_big_hist(df, "pre_week", "â¶ T-1 å‘¨ (çŸ­ç·šé è·‘å€)", "#ff4b4b", "å…¬å‘Šå‰ä¸€å‘¨ã€‚ç”¨æ–¼æ•æ‰æ¶ˆæ¯æ´©æ¼å¾Œçš„æœ€å¾Œè¡åˆºã€‚")
    create_big_hist(df, "announce_week", "â· T å‘¨ (å…¬å‘Šç•¶å‘¨ï¼šå¸‚å ´åæ‡‰)", "#ffaa00", "ç‡Ÿæ”¶é‡‹å‡ºã€‚æª¢é©—æ˜¯é©šå–œè¿½åƒ¹é‚„æ˜¯åˆ©å¤šå‡ºç›¡ã€‚")
    create_big_hist(df, "after_week_1", "â¸ T+1 å‘¨ (å…¬å‘Šå¾ŒçºŒï¼šæ…£æ€§å€)", "#32cd32", "å…¬å‘Šå¾ŒçºŒè¿½æ¼²æ„é¡˜ã€‚")
    create_big_hist(df, "after_month", "â¹ å…¬å‘Šå¾Œä¸€å€‹æœˆ (è¶¨å‹¢çµå±€)", "#1e90ff", "ä¸­ä½æ•¸è‹¥ä½æ–¼ 0 ä»£è¡¨å¤§å¤šæ•¸è‚¡ç¥¨åˆ©å¤šå‡ºç›¡å¾Œæœƒå›åã€‚")

    # D. å…§å»º AI è¨ºæ–· (æ•´åˆååº¦èˆ‡å³å°¾)
    st.divider()
    if st.button("ğŸ”’ å•Ÿå‹•å…§å»º Gemini å°ˆå®¶è¨ºæ–·"):
        st.session_state.run_final_ai = True

    if st.session_state.get("run_final_ai", False):
        with st.form("ai_form"):
            pw = st.text_input("å¯†ç¢¼ï¼š", type="password")
            if st.form_submit_button("åŸ·è¡Œåˆ†æ"):
                if pw == st.secrets["AI_ASK_PASSWORD"]:
                    if AI_AVAILABLE:
                        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
                        # ç¢ºä¿æ¨¡å‹åç¨±æ­£ç¢º
                        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                        target_model = next((m for m in models if "gemini-1.5-flash" in m), models[0])
                        model = genai.GenerativeModel(target_model)
                        
                        # æ¿ƒç¸®æç¤ºè©
                        final_prompt = (
                            f"åˆ†æå°è‚¡ {target_year} å¹´ã€‚æ¨£æœ¬ {total_n}ã€‚\n"
                            f"T-1æœˆå¹³å‡ {m_m:.1f}%, ä¸­ä½ {m_d:.1f}%, ååº¦ {m_s:.2f}ã€‚\n"
                            f"Tå‘¨å…¬å‘Šå¹³å‡ {a_m:.1f}%, T+1æœˆçµå±€ä¸­ä½ {f_d:.1f}%ã€‚\n"
                            f"è«‹é‡å°é€™äº›ã€è³‡è¨Šä¸å°ç¨±ã€èˆ‡ã€å³å°¾æ•ˆæ‡‰ã€æŒ‡æ¨™ï¼Œçµ¦äºˆæŠ•è³‡ç­–ç•¥å»ºè­°ã€‚"
                        )
                        
                        with st.spinner("AI æ­£åœ¨è§£æè³‡è¨Šå…ˆè¡Œç¨‹åº¦..."):
                            res = model.generate_content(final_prompt)
                            st.info("### ğŸ¤– å…§å»ºå°ˆå®¶å ±å‘Š")
                            st.markdown(res.text)
                    else: st.error("å¥—ä»¶ç¼ºå°‘")
                else: st.error("å¯†ç¢¼éŒ¯èª¤")

else:
    st.info("ğŸ’¡ æŸ¥ç„¡æ¨£æœ¬ã€‚")

st.markdown("---")
st.caption("Developed by StockRevenueLab | 2019-2025")
