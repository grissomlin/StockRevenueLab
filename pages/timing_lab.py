import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import urllib.parse
import plotly.graph_objects as go

# ========== 1. é é¢é…ç½® ==========
st.set_page_config(page_title="å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ | StockRevenueLab", layout="wide")

# ========== 2. å®‰å…¨è³‡æ–™åº«é€£ç·š ==========
@st.cache_resource
def get_engine():
    try:
        DB_PASSWORD = st.secrets["DB_PASSWORD"]
        PROJECT_REF = st.secrets["PROJECT_REF"]
        POOLER_HOST = st.secrets["POOLER_HOST"]
        encoded_password = urllib.parse.quote_plus(DB_PASSWORD)
        connection_string = f"postgresql://postgres.{PROJECT_REF}:{encoded_password}@{POOLER_HOST}:5432/postgres?sslmode=require"
        return create_engine(connection_string)
    except Exception:
        st.error("âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—")
        st.stop()

# ========== 3. æ•¸æ“šæ ¸å¿ƒé‹ç®—å‡½æ•¸ ==========
def get_distribution_text(df, col_name):
    """å°‡åˆ†ä½ˆæ•¸æ“šè½‰æ›ç‚ºæ–‡å­—ï¼Œæ–¹ä¾¿é¤µçµ¦ AI"""
    data = df[col_name].dropna()
    if data.empty: return "ç„¡æ•¸æ“š"
    counts, bins = np.histogram(data, bins=10) # ç‚ºäº†ç¯€çœ Tokenï¼Œåˆ† 10 å€‹å€é–“
    total = len(data)
    dist_str = ""
    for i in range(len(counts)):
        if counts[i] > 0:
            dist_str += f"- [{bins[i]:.1f}% ~ {bins[i+1]:.1f}%]: {counts[i]}æª” ({(counts[i]/total*100):.1f}%)\n"
    return dist_str

def create_big_hist(df, col_name, title, color, desc):
    data = df[col_name].dropna()
    if data.empty: return
    counts, bins = np.histogram(data, bins=20)
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    total = len(data)
    texts = [f"<b>{int(c)}æª”</b>" for c in counts]
    fig = go.Figure(data=[go.Bar(x=bin_centers, y=counts, text=texts, textposition='outside', marker_color=color)])
    fig.add_vline(x=0, line_dash="dash", line_color="black")
    fig.update_layout(title=dict(text=title, font=dict(size=20)), height=350, margin=dict(t=50, b=40))
    st.plotly_chart(fig, use_container_width=True)
    st.info(f"ğŸ’¡ **ç§‘å­¸è§£è®€ï¼š** {desc}")
    st.markdown("---")

# ========== 4. æ ¸å¿ƒ SQL ==========
@st.cache_data(ttl=3600)
def fetch_timing_data(year, metric_col, limit, keyword):
    engine = get_engine()
    minguo_year = int(year) - 1911
    query = f"""
    WITH raw_events AS (
        SELECT stock_id, stock_name, report_month, {metric_col}, remark,
               LAG({metric_col}) OVER (PARTITION BY stock_id ORDER BY report_month) as prev_metric
        FROM monthly_revenue
        WHERE report_month LIKE '{minguo_year}_%' OR report_month LIKE '{int(minguo_year)-1}_12'
    ),
    spark_events AS (
        SELECT *,
               CASE 
                 WHEN RIGHT(report_month, 2) = '12' THEN (LEFT(report_month, 3)::int + 1 + 1911)::text || '-01-10'
                 ELSE (LEFT(report_month, 3)::int + 1911)::text || '-' || LPAD((RIGHT(report_month, 2)::int + 1)::text, 2, '0') || '-10'
               END::date as base_date
        FROM raw_events
        WHERE {metric_col} >= {limit} 
          AND (prev_metric < {limit} OR prev_metric IS NULL)
          AND report_month LIKE '{minguo_year}_%'
          AND (remark LIKE '%%{keyword}%%' OR stock_name LIKE '%%{keyword}%%')
    ),
    weekly_calc AS (
        SELECT symbol, date, w_close,
               (w_close - LAG(w_close) OVER (PARTITION BY symbol ORDER BY date)) / 
               NULLIF(LAG(w_close) OVER (PARTITION BY symbol ORDER BY date), 0) * 100 as weekly_ret
        FROM stock_weekly_k
    ),
    final_detail AS (
        SELECT 
            e.stock_id, e.stock_name, e.report_month, e.{metric_col} as growth_val, e.remark,
            AVG(CASE WHEN c.date >= e.base_date - interval '38 days' AND c.date < e.base_date - interval '9 days' THEN c.weekly_ret END) * 4 as pre_month,
            AVG(CASE WHEN c.date >= e.base_date - interval '9 days' AND c.date <= e.base_date - interval '3 days' THEN c.weekly_ret END) as pre_week,
            AVG(CASE WHEN c.date > e.base_date - interval '3 days' AND c.date <= e.base_date + interval '4 days' THEN c.weekly_ret END) as announce_week,
            AVG(CASE WHEN c.date > e.base_date + interval '4 days' AND c.date <= e.base_date + interval '11 days' THEN c.weekly_ret END) as after_week_1,
            AVG(CASE WHEN c.date > e.base_date + interval '11 days' AND c.date <= e.base_date + interval '30 days' THEN c.weekly_ret END) as after_month
        FROM spark_events e
        JOIN weekly_calc c ON e.stock_id = SPLIT_PART(c.symbol, '.', 1)
        GROUP BY e.stock_id, e.stock_name, e.report_month, e.{metric_col}, e.remark, e.base_date
    )
    SELECT * FROM final_detail WHERE pre_week IS NOT NULL ORDER BY pre_month DESC;
    """
    with engine.connect() as conn:
        return pd.read_sql_query(text(query), conn)

# ========== 5. ä¸»ä»‹é¢é‚è¼¯ ==========
st.title("ğŸ•µï¸ ç‡Ÿæ”¶å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ 3.4 æ——è‰¦ç‰ˆ")

with st.sidebar:
    st.header("ğŸ”¬ åƒæ•¸è¨­å®š")
    target_year = st.sidebar.selectbox("åˆ†æå¹´åº¦", [str(y) for y in range(2025, 2019, -1)], index=1)
    study_metric = st.radio("æŒ‡æ¨™", ["yoy_pct", "mom_pct"])
    threshold = st.slider("é–€æª»", 30, 300, 100)
    search_key = st.text_input("é—œéµå­—", "")

df = fetch_timing_data(target_year, study_metric, threshold, search_key)

if not df.empty:
    # A. æ•¸æ“šçœ‹æ¿
    total_n = len(df)
    m_avg = round(df['pre_month'].mean(), 2)
    w_avg = round(df['pre_week'].mean(), 2)
    a_avg = round(df['announce_week'].mean(), 2)
    f_avg = round(df['after_month'].mean(), 2)

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("æ¨£æœ¬æ•¸", total_n)
    c2.metric("T-1æœˆå¹³å‡", f"{m_avg}%")
    c3.metric("T-1å‘¨å¹³å‡", f"{w_avg}%")
    c4.metric("Tå‘¨(å…¬å‘Š)å¹³å‡", f"{a_avg}%")
    c5.metric("T+1æœˆå¹³å‡", f"{f_avg}%")

    st.write("---")
    
    # B. åŸå§‹æ˜ç´°
    st.subheader(f"ğŸ† {target_year} å¹´ æ•¸æ“šæ˜ç´°æ¸…å–®")
    df['é€£çµ'] = df['stock_id'].apply(lambda x: f"https://www.wantgoo.com/stock/{x}/technical-chart")
    st.dataframe(df, use_container_width=True, column_config={"é€£çµ": st.column_config.LinkColumn("åœ–è¡¨", display_text="ğŸ”—")})

    st.write("---")

    # C. äº”éšæ®µåˆ†ä½ˆåœ– (èˆ‡æ–‡å­—è§£è®€)
    create_big_hist(df, "pre_month", "â“ª T-1 æœˆ (å¤§æˆ¶ä½ˆå±€å€)", "#8a2be2", "å…¬å‘Šå‰ä¸€å€‹æœˆèµ°å‹¢ï¼Œæª¢é©—å¤§è³‡é‡‘æ˜¯å¦æœ‰è¶…å‰ä½ˆå±€ç—•è·¡ã€‚")
    create_big_hist(df, "pre_week", "â¶ T-1 å‘¨ (çŸ­ç·šé è·‘å€)", "#ff4b4b", "å…¬å‘Šå‰ä¸€é€±èµ°å‹¢ï¼Œæª¢é©—çŸ­ç·šè³‡è¨Šé ˜å…ˆè€…æ˜¯å¦é€²è¡Œé è·‘ã€‚")
    create_big_hist(df, "announce_week", "â· T å‘¨ (å…¬å‘Šç•¶å‘¨)", "#ffaa00", "å…¬å‘Šé‚£ä¸€é€±è¡¨ç¾ã€‚æ­£å€¼ä»£è¡¨é©šå–œï¼Œè² å€¼ä»£è¡¨åˆ©å¤šå‡ºç›¡ã€‚")
    create_big_hist(df, "after_week_1", "â¸ T+1 å‘¨ (æ…£æ€§å€)", "#32cd32", "å…¬å‘Šå¾ŒçºŒè¿½æ¼²å‹•èƒ½ï¼Œæª¢é©—å¸‚å ´å…±è­˜å¼·åº¦ã€‚")
    create_big_hist(df, "after_month", "â¹ T+1 æœˆ (è¶¨å‹¢å€)", "#1e90ff", "ä¸€å€‹æœˆå¾Œçš„æ³¢æ®µçµå±€ï¼Œæª¢é©—çˆ†ç™¼æ˜¯å¦èƒ½å•Ÿå‹•é•·æ³¢æ®µã€‚")

    # D. AI æŒ‡ä»¤å€ (é—œéµï¼šå…¨æ•¸æ“šåˆ†ä½ˆå¸¶å…¥)
    st.divider()
    st.subheader("ğŸ¤– AI å…¨ç¶­åº¦åˆ†ä½ˆè¨ºæ–·")

    # è‡ªå‹•ç”Ÿæˆäº”éšæ®µåˆ†ä½ˆæ˜ç´°æ–‡å­—
    dist_reports = {
        "T-1æœˆ": get_distribution_text(df, "pre_month"),
        "T-1å‘¨": get_distribution_text(df, "pre_week"),
        "Tå‘¨": get_distribution_text(df, "announce_week"),
        "T+1å‘¨": get_distribution_text(df, "after_week_1"),
        "T+1æœˆ": get_distribution_text(df, "after_month")
    }

    prompt_text = (
        f"è«‹æ“”ä»»é‡åŒ–åˆ†æå¸«ï¼Œè§£è®€å°è‚¡ {target_year} å¹´ç‡Ÿæ”¶çˆ†ç™¼å¾Œçš„äº”éšæ®µè‚¡åƒ¹è¡Œç‚ºã€‚\n"
        f"ã€å…¨æ¨£æœ¬çµ±è¨ˆã€‘ï¼š{total_n} æª”ã€‚å¹³å‡å ±é…¬ï¼šT-1æœˆ {m_avg}%ï¼ŒT-1å‘¨ {w_avg}%ï¼ŒTå‘¨ {a_avg}%ï¼ŒT+1æœˆ {f_avg}%ã€‚\n\n"
        f"ã€äº”éšæ®µè©³ç´°åˆ†ä½ˆæ•¸æ“šã€‘ï¼š\n"
        f"1. T-1æœˆ(ä½ˆå±€å€)åˆ†ä½ˆï¼š\n{dist_reports['T-1æœˆ']}\n"
        f"2. T-1å‘¨(é è·‘å€)åˆ†ä½ˆï¼š\n{dist_reports['T-1å‘¨']}\n"
        f"3. Tå‘¨(å…¬å‘Šå€)åˆ†ä½ˆï¼š\n{dist_reports['Tå‘¨']}\n"
        f"4. T+1å‘¨(æ…£æ€§å€)åˆ†ä½ˆï¼š\n{dist_reports['T+1å‘¨']}\n"
        f"5. T+1æœˆ(æ³¢æ®µå€)åˆ†ä½ˆï¼š\n{dist_reports['T+1æœˆ']}\n\n"
        f"è«‹åˆ†æï¼šåˆ†ä½ˆæ•¸æ“šä¸­æ˜¯å¦å‡ºç¾ã€å°‘æ•¸æ¬Šå€¼è‚¡å¸¶å‹•å¹³å‡ã€é‚„æ˜¯ã€æ™®æ¼²è¡Œæƒ…ã€ï¼Ÿåœ¨å“ªå€‹éšæ®µé€²å ´æœ€èƒ½é¿é–‹åˆ©å¤šå‡ºç›¡çš„é¢¨éšªï¼Ÿ"
    )

    cp, cl = st.columns([2, 1])
    with cp: st.code(prompt_text, language="text")
    with cl:
        encoded_p = urllib.parse.quote(prompt_text)
        st.link_button("â™Š ç›´æ¥è©¢å• Gemini (æ¨è–¦æ•¸æ“šåˆ†æ)", "https://gemini.google.com/app")
        st.link_button("ğŸ”¥ é–‹å•Ÿ ChatGPT (å…¨æ•¸æ“šå¸¶å…¥)", f"https://chatgpt.com/?q={encoded_p}")
        if st.button("ğŸ”’ å¯†ç¢¼ä¿è­·ï¼šè§£é–ç›´æ¥æå•"):
            st.session_state.unlock = True

    if st.session_state.get("unlock", False):
        with st.form("pw"):
            p = st.text_input("å¯†ç¢¼", type="password")
            if st.form_submit_button("é©—è­‰"):
                if p == st.secrets["AI_ASK_PASSWORD"]:
                    st.markdown(f'<meta http-equiv="refresh" content="0;url=https://chatgpt.com/?q={encoded_p}">', unsafe_allow_html=True)
                else: st.error("å¯†ç¢¼éŒ¯èª¤")

else:
    st.info("ğŸ’¡ æŸ¥ç„¡ç¬¦åˆæ¨£æœ¬ã€‚")
