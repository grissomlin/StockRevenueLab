import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
import urllib.parse
import plotly.graph_objects as go

# ========== 1. é é¢é…ç½® ==========
st.set_page_config(page_title="å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ | StockRevenueLab", layout="wide")

# ========== 2. å®‰å…¨è³‡æ–™åº«é€£ç·š ==========
@st.cache_resource
def get_engine():
    try:
        DB_PASSWORD = st.secrets["DB_PASSWORD"]
        PROJECT_REF = st.secrets["PROJECT_REF"]
        POOLER_HOST = st.secrets["POOLER_HOST"]
        encoded_password = urllib.parse.quote_plus(DB_PASSWORD)
        connection_string = f"postgresql://postgres.{PROJECT_REF}:{encoded_password}@{POOLER_HOST}:5432/postgres?sslmode=require"
        return create_engine(connection_string)
    except Exception:
        st.error("âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—")
        st.stop()

# ========== 3. ç¹ªåœ–è¼”åŠ©å‡½æ•¸ (å¤§å‹å‚ç›´åˆ†ä½ˆåœ–) ==========
def create_big_hist(df, col_name, title, color, desc):
    if df[col_name].dropna().empty: return go.Figure()
    
    # è¨ˆç®—åˆ†ä½ˆ
    counts, bins = np.histogram(df[col_name].dropna(), bins=25)
    bin_centers = 0.5 * (bins[:-1] + bins[1:])
    total = len(df)
    
    # æ¨™ç±¤é¡¯ç¤ºåœ¨æŸ±ç‹€åœ–ä¸Šæ–¹ (é–å®š 1 ä½å°æ•¸é¡¯ç¤º)
    texts = [f"<b>{int(c)}æª”</b><br>{(c/total*100):.1f}%" if c > 0 else "" for c in counts]
    
    fig = go.Figure(data=[
        go.Bar(
            x=bin_centers,
            y=counts,
            text=texts,
            textposition='outside',
            marker_color=color,
            hovertemplate="æ¼²è·Œå€é–“: %{x:.2f}%<br>å®¶æ•¸: %{y}æª”<extra></extra>"
        )
    ])
    
    fig.add_vline(x=0, line_dash="dash", line_color="black", line_width=2)
    fig.update_layout(
        title=dict(text=title, font=dict(size=22)),
        xaxis_title="æ¼²è·Œå¹… %",
        yaxis_title="å®¶æ•¸ (æª”)",
        margin=dict(t=80, b=40, l=50, r=50),
        height=400,
        showlegend=False
    )
    
    st.plotly_chart(fig, use_container_width=True)
    st.info(f"ğŸ’¡ **ç§‘å­¸è§£è®€ï¼š** {desc}")
    st.markdown("---")

# ========== 4. æ ¸å¿ƒæ¨™é¡Œ ==========
st.title("ğŸ•µï¸ ç‡Ÿæ”¶å…¬å‘Šè¡Œç‚ºç ”ç©¶å®¤ 3.2 æ——è‰¦ç‰ˆ")

# --- å´é‚Šæ¬„æ§åˆ¶ ---
with st.sidebar:
    st.header("ğŸ”¬ ç­–ç•¥åƒæ•¸è¨­å®š")
    target_year = st.selectbox("åˆ†æå¹´åº¦", [str(y) for y in range(2025, 2019, -1)], index=1)
    study_metric = st.radio("æˆé•·æŒ‡æ¨™", ["yoy_pct", "mom_pct"])
    threshold = st.slider(f"è¨­å®š {study_metric} çˆ†ç™¼é–€æª» %", 30, 300, 100)
    search_remark = st.text_input("ğŸ” é—œéµå­—æœå°‹ (å¦‚: äº¤å±‹, æ¨™æ¡ˆ, æ”¹è‰¯)", "")

# --- æ ¸å¿ƒ SQL (æŠ“å–äº”éšæ®µæ•¸æ“š) ---
@st.cache_data(ttl=3600)
def fetch_timing_data(year, metric_col, limit, keyword):
    engine = get_engine()
    minguo_year = int(year) - 1911
    query = f"""
    WITH raw_events AS (
        SELECT stock_id, stock_name, report_month, {metric_col}, remark,
               LAG({metric_col}) OVER (PARTITION BY stock_id ORDER BY report_month) as prev_metric
        FROM monthly_revenue
        WHERE report_month LIKE '{minguo_year}_%' OR report_month LIKE '{int(minguo_year)-1}_12'
    ),
    spark_events AS (
        SELECT *,
               CASE 
                 WHEN RIGHT(report_month, 2) = '12' THEN (LEFT(report_month, 3)::int + 1 + 1911)::text || '-01-10'
                 ELSE (LEFT(report_month, 3)::int + 1911)::text || '-' || LPAD((RIGHT(report_month, 2)::int + 1)::text, 2, '0') || '-10'
               END::date as base_date
        FROM raw_events
        WHERE {metric_col} >= {limit} 
          AND (prev_metric < {limit} OR prev_metric IS NULL)
          AND report_month LIKE '{minguo_year}_%'
          AND (remark LIKE '%%{keyword}%%' OR stock_name LIKE '%%{keyword}%%')
    ),
    weekly_calc AS (
        SELECT symbol, date, w_close,
               (w_close - LAG(w_close) OVER (PARTITION BY symbol ORDER BY date)) / 
               NULLIF(LAG(w_close) OVER (PARTITION BY symbol ORDER BY date), 0) * 100 as weekly_ret
        FROM stock_weekly_k
    ),
    final_detail AS (
        SELECT 
            e.stock_id, e.stock_name, e.report_month, 
            e.{metric_col} as growth_val, 
            e.remark,
            AVG(CASE WHEN c.date >= e.base_date - interval '38 days' AND c.date < e.base_date - interval '9 days' THEN c.weekly_ret END) * 4 as pre_month,
            AVG(CASE WHEN c.date >= e.base_date - interval '9 days' AND c.date <= e.base_date - interval '3 days' THEN c.weekly_ret END) as pre_week,
            AVG(CASE WHEN c.date > e.base_date - interval '3 days' AND c.date <= e.base_date + interval '4 days' THEN c.weekly_ret END) as announce_week,
            AVG(CASE WHEN c.date > e.base_date + interval '4 days' AND c.date <= e.base_date + interval '11 days' THEN c.weekly_ret END) as after_week_1,
            AVG(CASE WHEN c.date > e.base_date + interval '11 days' AND c.date <= e.base_date + interval '30 days' THEN c.weekly_ret END) as after_month
        FROM spark_events e
        JOIN weekly_calc c ON e.stock_id = SPLIT_PART(c.symbol, '.', 1)
        GROUP BY e.stock_id, e.stock_name, e.report_month, e.{metric_col}, e.remark, e.base_date
    )
    SELECT * FROM final_detail WHERE pre_week IS NOT NULL ORDER BY pre_month DESC;
    """
    with engine.connect() as conn:
        return pd.read_sql_query(text(query), conn)

df = fetch_timing_data(target_year, study_metric, threshold, search_remark)

if not df.empty:
    # --- A. çµ±è¨ˆçœ‹æ¿ ---
    total_n = len(df)
    stats = {
        "m_avg": round(df['pre_month'].mean(), 2),
        "w_avg": round(df['pre_week'].mean(), 2),
        "ann_avg": round(df['announce_week'].mean(), 2),
        "after_avg": round(df['after_month'].mean(), 2)
    }
    
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("æ¨£æœ¬æ•¸", total_n)
    c2.metric("T-1æœˆå¹³å‡", f"{stats['m_avg']}%")
    c3.metric("T-1å‘¨å¹³å‡", f"{stats['w_avg']}%")
    c4.metric("Tå‘¨å¹³å‡", f"{stats['ann_avg']}%")
    c5.metric("T+1æœˆå¹³å‡", f"{stats['after_avg']}%")

    st.write("---")
    
    # --- B. åŸå§‹æ˜ç´°æ¸…å–® (ä¿ç•™åŠŸèƒ½) ---
    st.subheader(f"ğŸ† {target_year} å¹´ åˆæ¬¡çˆ†ç™¼æ˜ç´°æ¸…å–®")
    df['é€£çµ'] = df['stock_id'].apply(lambda x: f"https://www.wantgoo.com/stock/{x}/technical-chart")
    
    display_df = df.rename(columns={
        "stock_id": "ä»£è™Ÿ", "stock_name": "åç¨±", "report_month": "æœˆä»½",
        "growth_val": f"{study_metric}%", 
        "pre_month": "T-1æœˆ%", "pre_week": "T-1å‘¨%", "announce_week": "Tå‘¨%", 
        "after_week_1": "T+1å‘¨%", "after_month": "ä¸€å€‹æœˆå¾Œ%", "remark": "å‚™è¨»"
    })

    st.dataframe(
        display_df.style.background_gradient(subset=["T-1æœˆ%", "T-1å‘¨%", "Tå‘¨%", "T+1å‘¨%", "ä¸€å€‹æœˆå¾Œ%"], cmap="RdYlGn"),
        use_container_width=True, height=450,
        column_config={
            "é€£çµ": st.column_config.LinkColumn("åœ–è¡¨", display_text="ğŸ”—"),
            f"{study_metric}%": st.column_config.NumberColumn(format="%.2f"),
            "T-1æœˆ%": st.column_config.NumberColumn(format="%.2f"),
            "T-1å‘¨%": st.column_config.NumberColumn(format="%.2f"),
            "Tå‘¨%": st.column_config.NumberColumn(format="%.2f"),
            "T+1å‘¨%": st.column_config.NumberColumn(format="%.2f"),
            "ä¸€å€‹æœˆå¾Œ%": st.column_config.NumberColumn(format="%.2f")
        },
        hide_index=True
    )

    st.write("---")

    # --- C. äº”å¼µå¤§å‹å‚ç›´åˆ†ä½ˆåœ– (å«èªªæ˜) ---
    st.subheader("ğŸ“Š éšæ®µå ±é…¬åˆ†ä½ˆè¶¨å‹¢")
    
    create_big_hist(df, "pre_month", "â“ª T-1 æœˆ (å¤§æˆ¶ä½ˆå±€å€)", "#8a2be2", "å…¬å‘Šå‰ä¸€å€‹æœˆçš„èµ°å‹¢ã€‚è‹¥æ­¤å€é–“æ­£å€¼æ¯”ä¾‹é«˜ï¼Œä»£è¡¨å¤§è³‡é‡‘å·²æå‰éƒ¨ç½²ã€‚")
    create_big_hist(df, "pre_week", "â¶ T-1 å‘¨ (çŸ­ç·šé è·‘å€)", "#ff4b4b", "å…¬å‘Šå‰æœ€å¾Œä¸€é€±ã€‚é€šå¸¸æ˜¯çŸ­ç·šæ¥­å…§äººå£«æˆ–å¾—çŸ¥æ¶ˆæ¯è€…é€²è¡Œé è·‘ã€‚")
    create_big_hist(df, "announce_week", "â· T å‘¨ (å…¬å‘Šç•¶å‘¨ï¼šå¸‚å ´åæ‡‰)", "#ffaa00", "ç‡Ÿæ”¶æ­£å¼å…¬å‘Šé‚£ä¸€é€±ã€‚ç”¨æ–¼è§€å¯Ÿå¸‚å ´æ˜¯ã€åˆ©å¤šå‡ºç›¡ã€é‚„æ˜¯ã€åˆ©å¤šè¿½åƒ¹ã€ã€‚")
    create_big_hist(df, "after_week_1", "â¸ T+1 å‘¨ (å…¬å‘Šå¾Œï¼šå»¶çºŒå€)", "#32cd32", "å…¬å‘Šå¾Œä¸€é€±ã€‚åˆ¤æ–·åˆ©å¤šæ¶ˆæ¯æ˜¯å¦å…·æœ‰çŸ­ç·šå‹•èƒ½ã€‚")
    create_big_hist(df, "after_month", "â¹ å…¬å‘Šå¾Œä¸€å€‹æœˆ (æ³¢æ®µè¶¨å‹¢å€)", "#1e90ff", "ä¸€å€‹æœˆå¾Œçš„è¡¨ç¾ã€‚ç”¨æ–¼åˆ¤æ–·çˆ†ç™¼æ˜¯å¦æˆåŠŸå•Ÿå‹•æ³¢æ®µä¸»å‡æ®µã€‚")

    # --- D. AI æŒ‡ä»¤èˆ‡ Gemini å„ªå…ˆæŒ‰éˆ• ---
    st.divider()
    st.subheader("ğŸ¤– AI å…¨éšæ®µè¡Œç‚ºè¨ºæ–·")
    
    prompt_text = (
        f"åˆ†æå°è‚¡ {target_year} å¹´ç‡Ÿæ”¶çˆ†ç™¼è¡Œç‚ºã€‚\n"
        f"æ•¸æ“šæ‘˜è¦ï¼šæ¨£æœ¬æ•¸ {total_n}ã€‚å¹³å‡å ±é…¬ï¼šT-1æœˆ {stats['m_avg']}%ï¼ŒT-1å‘¨ {stats['w_avg']}%ï¼ŒTå‘¨ {stats['ann_avg']}%ï¼ŒT+1æœˆ {stats['after_avg']}%ã€‚\n"
        f"è«‹é‡å°é€™äº”éšæ®µçš„åˆ†ä½ˆæ•¸æ“šï¼Œåˆ¤æ–·è©²å¹´åº¦å¸‚å ´è³‡è¨Šé ˜å…ˆçš„æƒ…æ³ï¼Œä¸¦çµ¦äºˆç­–ç•¥å»ºè­°ã€‚"
    )

    c1, c2 = st.columns([2, 1])
    with c1:
        st.write("ğŸ“‹ **AI çµ±è¨ˆç‰¹å¾µæŒ‡ä»¤ (å·²é–å®šå…©ä½å°æ•¸)**")
        st.code(prompt_text, language="text")
    
    with c2:
        encoded_p = urllib.parse.quote(prompt_text)
        # Gemini å„ªå…ˆé¡¯ç¤º
        st.link_button("â™Š ç›´æ¥è©¢å• Gemini (éœ€è²¼ä¸Š)", "https://gemini.google.com/app")
        st.link_button("ğŸ”¥ é–‹å•Ÿ ChatGPT (å…¨è‡ªå‹•å¸¶å…¥)", f"https://chatgpt.com/?q={encoded_p}")
        st.link_button("ğŸŒ é–‹å•Ÿ Claude (éœ€è²¼ä¸Š)", "https://claude.ai/")

        # å¯†ç¢¼ä¿è­·æŒ‰éˆ•
        if st.button("ğŸ”’ å¯†ç¢¼é©—è­‰ï¼šç›´æ¥æå• AI"):
            st.session_state.show_pw_dialog = True

    if st.session_state.get("show_pw_dialog", False):
        with st.form("pw_form"):
            user_pw = st.text_input("è¼¸å…¥ç ”ç©¶å“¡å¯†ç¢¼ï¼š", type="password")
            if st.form_submit_button("åŸ·è¡Œé©—è­‰"):
                if user_pw == st.secrets["AI_ASK_PASSWORD"]:
                    st.success("å¯†ç¢¼æ­£ç¢ºï¼æ­£åœ¨å‰å¾€åˆ†æå¹³å°...")
                    st.markdown(f'<meta http-equiv="refresh" content="0;url=https://chatgpt.com/?q={encoded_p}">', unsafe_allow_html=True)
                else:
                    st.error("å¯†ç¢¼éŒ¯èª¤ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")

else:
    st.info("ğŸ’¡ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„å…¬å¸ã€‚")

st.markdown("---")
st.caption("Developed by StockRevenueLab | æ•¸æ“šé€±æœŸï¼š2019-2025")
